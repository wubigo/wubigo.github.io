<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>GPT on wubigo</title>
    <link>https://wubigo.com/tags/gpt/</link>
    <description>Recent content in GPT on wubigo</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 27 Mar 2024 09:43:56 +0800</lastBuildDate>
    
	<atom:link href="https://wubigo.com/tags/gpt/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>本地大模型知识库问答</title>
      <link>https://wubigo.com/post/chatchat-llm-notes/</link>
      <pubDate>Wed, 27 Mar 2024 09:43:56 +0800</pubDate>
      
      <guid>https://wubigo.com/post/chatchat-llm-notes/</guid>
      <description> 本地部署 下载大模型 大模型下载
 https://www.modelscope.cn/models/AI-ModelScope/bge-large-zh-v1.5 https://www.modelscope.cn/models/ZhipuAI/chatglm3-6b  ChatGLM3 git clone https://github.com/THUDM/ChatGLM3 cd ChatGLM3 pip install -r requirements.txt python from transformers import AutoTokenizer, AutoModel tokenizer = AutoTokenizer.from_pretrained(&amp;quot;/home/wubigo/model/ZhipuAI/chatglm3-6b&amp;quot;, trust_remote_code=True) model = AutoModel.from_pretrained(&amp;quot;/home/wubigo/model/ZhipuAI/chatglm3-6b&amp;quot;, trust_remote_code=True, device=&#39;cuda&#39;) model = model.eval() response, history = model.chat(tokenizer, &amp;quot;你好&amp;quot;, history=[])  初始化知识库 git clone --recursive https://github.com/chatchat-space/Langchain-Chatchat.git cd Langchain-Chatchat pip install -r requirements.txt python copy_config_example.py python init_database.py --recreate-vs  启动服务 python startup.py -a  </description>
    </item>
    
  </channel>
</rss>