<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>LLM on wubigo</title>
    <link>https://wubigo.com/tags/llm/</link>
    <description>Recent content in LLM on wubigo</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 18 Apr 2023 11:00:40 +0800</lastBuildDate>
    
	<atom:link href="https://wubigo.com/tags/llm/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Llm Notes</title>
      <link>https://wubigo.com/post/llm-notes/</link>
      <pubDate>Tue, 18 Apr 2023 11:00:40 +0800</pubDate>
      
      <guid>https://wubigo.com/post/llm-notes/</guid>
      <description>OpenAssistant Democratizing Large Language Model Alignment
Aligning large language models (LLMs) with human preferences has proven to drastically improve usability and has driven rapid adoption as demonstrated by ChatGPT. Alignment techniques such as supervised fine-tuning (SFT) and reinforcement learning from human feedback (RLHF) greatly reduce the required skill and domain knowledge to effectively harness the capabilities of LLMs, increasing their accessibility and utility across various domains.</description>
    </item>
    
  </channel>
</rss>