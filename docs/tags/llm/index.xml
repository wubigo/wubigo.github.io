<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>LLM on wubigo</title>
    <link>https://wubigo.com/tags/llm/</link>
    <description>Recent content in LLM on wubigo</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 27 Mar 2024 09:43:56 +0800</lastBuildDate>
    
	<atom:link href="https://wubigo.com/tags/llm/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>本地大模型知识库问答</title>
      <link>https://wubigo.com/post/chatchat-llm-notes/</link>
      <pubDate>Wed, 27 Mar 2024 09:43:56 +0800</pubDate>
      
      <guid>https://wubigo.com/post/chatchat-llm-notes/</guid>
      <description> 本地部署 下载大模型 大模型下载
 https://www.modelscope.cn/models/AI-ModelScope/bge-large-zh-v1.5 https://www.modelscope.cn/models/ZhipuAI/chatglm3-6b  ChatGLM3 git clone https://github.com/THUDM/ChatGLM3 cd ChatGLM3 pip install -r requirements.txt python from transformers import AutoTokenizer, AutoModel tokenizer = AutoTokenizer.from_pretrained(&amp;quot;/home/wubigo/model/ZhipuAI/chatglm3-6b&amp;quot;, trust_remote_code=True) model = AutoModel.from_pretrained(&amp;quot;/home/wubigo/model/ZhipuAI/chatglm3-6b&amp;quot;, trust_remote_code=True, device=&#39;cuda&#39;) model = model.eval() response, history = model.chat(tokenizer, &amp;quot;你好&amp;quot;, history=[])  初始化知识库 git clone --recursive https://github.com/chatchat-space/Langchain-Chatchat.git cd Langchain-Chatchat pip install -r requirements.txt python copy_config_example.py python init_database.py --recreate-vs  启动服务 python startup.py -a  </description>
    </item>
    
    <item>
      <title>LLM Notes</title>
      <link>https://wubigo.com/post/llm-notes/</link>
      <pubDate>Tue, 18 Apr 2023 11:00:40 +0800</pubDate>
      
      <guid>https://wubigo.com/post/llm-notes/</guid>
      <description>大模型下载 pip install modelscope from modelscope.hub.snapshot_download import snapshot_download model_dir = snapshot_download(&#39;ZhipuAI/chatglm3-6b&#39;, cache_dir=&#39;./model&#39;, revision=&#39;master&#39;)  下载 https://www.modelscope.cn/models/ZhipuAI/chatglm2-6b
nvidia-smi Failed to initialize NVML: Driver/library version mismatch 这个问题出现的原因是kernel mod 的 Nvidia driver 的版本没有更新，一般情况下，重启机器就能够解决， 如果因为某些原因不能够重启的话，也有办法reload kernel mod。
简单来看，就两步
 unload nvidia kernel mod reload nvidia kernel mod  执行起来就是
sudo rmmod nvidia sudo nvidia-smi  分词器(Tokenizer) tokenization算法大致经历了从word/char到subword的进化.
目前有三种主流的Subword分词算法，分别是Byte Pair Encoding (BPE), WordPiece和Unigram Language Model
Back in the ancient times, before 2013, we usually encoded basic unigram tokens using simple 1’s and 0’s in a process called One-Hot encoding.</description>
    </item>
    
  </channel>
</rss>