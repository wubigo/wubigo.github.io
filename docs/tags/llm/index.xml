<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>LLM on wubigo</title>
    <link>https://wubigo.com/tags/llm/</link>
    <description>Recent content in LLM on wubigo</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 17 Jun 2025 16:42:02 +0800</lastBuildDate>
    
	<atom:link href="https://wubigo.com/tags/llm/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>åœ¨ Windows ä¸Šå®‰è£… llama-cpp-python å®Œæ•´æŒ‡å—</title>
      <link>https://wubigo.com/post/llama-cpp-python-setup-on-windows/</link>
      <pubDate>Tue, 17 Jun 2025 16:42:02 +0800</pubDate>
      
      <guid>https://wubigo.com/post/llama-cpp-python-setup-on-windows/</guid>
      <description>åœ¨ Windows ä¸Šå®‰è£… llama-cpp-python å®Œæ•´æŒ‡å—
ä»¥ä¸‹æ˜¯åœ¨ Windows ç³»ç»Ÿä¸Šå®‰è£…æ”¯æŒ GPU åŠ é€Ÿçš„ llama-cpp-python çš„è¯¦ç»†æ­¥éª¤ï¼ŒåŒ…å«å¸¸è§é—®é¢˜è§£å†³æ–¹æ¡ˆå’Œæ€§èƒ½ä¼˜åŒ–æŠ€å·§
ğŸ›  å®‰è£…å‰å‡†å¤‡ 1. ç³»ç»Ÿè¦æ±‚  æ“ä½œç³»ç»Ÿï¼šWindows 10 (64ä½) Pythonï¼š3.10 æˆ–æ›´é«˜ç‰ˆæœ¬ å†…å­˜ï¼šè‡³å°‘ 16GB RAM æ˜¾å¡ï¼šAMD GPU (æ”¯æŒ Vulkan)  2. å®‰è£…å¿…å¤‡ç»„ä»¶  å®‰è£… Python
python Python 3.10.9 (tags/v3.10.9:1dd9be6, Dec 6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)] on win32 Type &amp;quot;help&amp;quot;, &amp;quot;copyright&amp;quot;, &amp;quot;credits&amp;quot; or &amp;quot;license&amp;quot; for more information  å®‰è£… Visual Studio Build Tools
 ä¸‹è½½ Visual Studio 2022 å®‰è£…æ—¶é€‰æ‹©ï¼š  &amp;ldquo;Desktop development with C++&amp;rdquo; &amp;ldquo;Windows 10&amp;frasl;11 SDK&amp;rdquo; &amp;ldquo;C++ CMake tools&amp;rdquo;   å®‰è£… CUDA Toolkit (NVIDIA ç”¨æˆ·)</description>
    </item>
    
    <item>
      <title>æœ¬åœ°å¤§æ¨¡å‹çŸ¥è¯†åº“é—®ç­”</title>
      <link>https://wubigo.com/post/chatchat-llm-notes/</link>
      <pubDate>Wed, 27 Mar 2024 09:43:56 +0800</pubDate>
      
      <guid>https://wubigo.com/post/chatchat-llm-notes/</guid>
      <description> æœ¬åœ°éƒ¨ç½² ä¸‹è½½å¤§æ¨¡å‹ å¤§æ¨¡å‹ä¸‹è½½
 https://www.modelscope.cn/models/AI-ModelScope/bge-large-zh-v1.5 https://www.modelscope.cn/models/ZhipuAI/chatglm3-6b  ChatGLM3 git clone https://github.com/THUDM/ChatGLM3 cd ChatGLM3 pip install -r requirements.txt python from transformers import AutoTokenizer, AutoModel tokenizer = AutoTokenizer.from_pretrained(&amp;quot;/home/wubigo/model/ZhipuAI/chatglm3-6b&amp;quot;, trust_remote_code=True) model = AutoModel.from_pretrained(&amp;quot;/home/wubigo/model/ZhipuAI/chatglm3-6b&amp;quot;, trust_remote_code=True, device=&#39;cuda&#39;) model = model.eval() response, history = model.chat(tokenizer, &amp;quot;ä½ å¥½&amp;quot;, history=[])  åˆå§‹åŒ–çŸ¥è¯†åº“ git clone --recursive https://github.com/chatchat-space/Langchain-Chatchat.git cd Langchain-Chatchat pip install -r requirements.txt python copy_config_example.py python init_database.py --recreate-vs  å¯åŠ¨æœåŠ¡ python startup.py -a  </description>
    </item>
    
    <item>
      <title>LLM Notes</title>
      <link>https://wubigo.com/post/llm-notes/</link>
      <pubDate>Tue, 18 Apr 2023 11:00:40 +0800</pubDate>
      
      <guid>https://wubigo.com/post/llm-notes/</guid>
      <description>å¤§æ¨¡å‹ä¸‹è½½ pip install modelscope from modelscope.hub.snapshot_download import snapshot_download model_dir = snapshot_download(&#39;ZhipuAI/chatglm3-6b&#39;, cache_dir=&#39;./model&#39;, revision=&#39;master&#39;)  ä¸‹è½½ https://www.modelscope.cn/models/ZhipuAI/chatglm2-6b
nvidia-smi Failed to initialize NVML: Driver/library version mismatch è¿™ä¸ªé—®é¢˜å‡ºç°çš„åŸå› æ˜¯kernel mod çš„ Nvidia driver çš„ç‰ˆæœ¬æ²¡æœ‰æ›´æ–°ï¼Œä¸€èˆ¬æƒ…å†µä¸‹ï¼Œé‡å¯æœºå™¨å°±èƒ½å¤Ÿè§£å†³ï¼Œ å¦‚æœå› ä¸ºæŸäº›åŸå› ä¸èƒ½å¤Ÿé‡å¯çš„è¯ï¼Œä¹Ÿæœ‰åŠæ³•reload kernel modã€‚
ç®€å•æ¥çœ‹ï¼Œå°±ä¸¤æ­¥
 unload nvidia kernel mod reload nvidia kernel mod  æ‰§è¡Œèµ·æ¥å°±æ˜¯
sudo rmmod nvidia sudo nvidia-smi  åˆ†è¯å™¨(Tokenizer) tokenizationç®—æ³•å¤§è‡´ç»å†äº†ä»word/charåˆ°subwordçš„è¿›åŒ–.
ç›®å‰æœ‰ä¸‰ç§ä¸»æµçš„Subwordåˆ†è¯ç®—æ³•ï¼Œåˆ†åˆ«æ˜¯Byte Pair Encoding (BPE), WordPieceå’ŒUnigram Language Model
Back in the ancient times, before 2013, we usually encoded basic unigram tokens using simple 1â€™s and 0â€™s in a process called One-Hot encoding.</description>
    </item>
    
    <item>
      <title>machine learning basic</title>
      <link>https://wubigo.com/post/2017-01-03-machinelearningbasic/</link>
      <pubDate>Tue, 25 Apr 2017 15:41:55 +0800</pubDate>
      
      <guid>https://wubigo.com/post/2017-01-03-machinelearningbasic/</guid>
      <description>æœºå™¨å­¦ä¹ æ˜¯ç»Ÿè®¡æ¨¡å‹ å¯¹æ–‡æœ¬æ ‡ç­¾é…å¯¹è¿›è¡Œç»Ÿè®¡æ¨¡å‹è®­ç»ƒï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿä½¿ç”¨ä»£è¡¨æ¶ˆæ¯æ„å›¾çš„é¢„å®šä¹‰æ ‡ç­¾å¯¹æœªçŸ¥è¾“å…¥æ–‡æœ¬è¿›è¡Œåˆ†ç±»
a statistical model is trained on text-label pairings, enabling the model to classify unknown input text with a pre-defined label representing the intention of the message
Early neural networks Although the core ideas of neural networks were investigated in toy forms as early as the 1950s, the approach took decades to really get started. For a long time, the missing piece was a lack of an efficient way to train large neural networks.</description>
    </item>
    
  </channel>
</rss>