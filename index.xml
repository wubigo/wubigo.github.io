<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>NgAPP on NgAPP</title>
    <link>https://wubigo.com/</link>
    <description>Recent content in NgAPP on NgAPP</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 24 Nov 2020 09:26:24 +0800</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Elastic Search Notes</title>
      <link>https://wubigo.com/post/elastic-search-notes/</link>
      <pubDate>Tue, 24 Nov 2020 09:26:24 +0800</pubDate>
      
      <guid>https://wubigo.com/post/elastic-search-notes/</guid>
      <description>&lt;p&gt;“The act of storing data in Elasticsearch is called indexing, but before we can index a document, we need to decide where to store it”&lt;/p&gt;

&lt;p&gt;“Relational DB  ⇒ Databases ⇒ Tables ⇒ Rows      ⇒ Columns
Elasticsearch  ⇒ Indices   ⇒ Types  ⇒ Documents ⇒ Fields”&lt;/p&gt;

&lt;p&gt;“_index
Where the document lives&lt;/p&gt;

&lt;p&gt;_type
The class of object that the document represents&lt;/p&gt;

&lt;p&gt;_id
The unique identifier for the document”&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Skywalking on K8s</title>
      <link>https://wubigo.com/post/skywalking-on-k8s/</link>
      <pubDate>Wed, 04 Nov 2020 15:58:19 +0800</pubDate>
      
      <guid>https://wubigo.com/post/skywalking-on-k8s/</guid>
      <description>

&lt;h2 id=&#34;安装eck-禁用tls&#34;&gt;安装ECK(禁用TLS)&lt;/h2&gt;

&lt;p&gt;[](/post/elastic-cloud-on-k8s/)&lt;/p&gt;

&lt;h2 id=&#34;安装helm3&#34;&gt;安装helm3&lt;/h2&gt;

&lt;h2 id=&#34;安装skywalking8&#34;&gt;安装skywalking8&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;git clone git@github.com:wubigo/skywalking-kubernetes.git
cd skywalking-kubernetes/chart
helm repo add elastic https://helm.elastic.co
helm dep up skywalking
export SKYWALKING_RELEASE_NAME=skywalking
export SKYWALKING_RELEASE_NAMESPACE=default  
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;配置ES&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;skywalking/values-my-es.yaml&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;oap:
  image:
    tag: 8.1.0-es7      # Set the right tag according to the existing Elasticsearch version
  storageType: elasticsearch7

ui:
  image:
    tag: 8.1.0

elasticsearch:
  enabled: false
  config:               
    host: 10.101.24.19
    port:
      http: 9200
    user: &amp;quot;elastic&amp;quot;         #[optional]
    password: &amp;quot;8FfgPZu0985bAm2x4243ncxJ&amp;quot;     # [optional]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;helm install &amp;quot;${SKYWALKING_RELEASE_NAME}&amp;quot; skywalking -n &amp;quot;${SKYWALKING_RELEASE_NAMESPACE}&amp;quot; \
  -f ./skywalking/values-my-es.yaml

&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;检查&#34;&gt;检查&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;kubectl get svc
NAME                      TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)               AGE
kubernetes                ClusterIP   10.96.0.1        &amp;lt;none&amp;gt;        443/TCP               4h31m
quickstart-es-default     ClusterIP   None             &amp;lt;none&amp;gt;        9200/TCP              123m
quickstart-es-http        ClusterIP   10.101.24.19     &amp;lt;none&amp;gt;        9200/TCP              123m
quickstart-es-transport   ClusterIP   None             &amp;lt;none&amp;gt;        9300/TCP              123m
skywalking-oap            ClusterIP   10.105.155.189   &amp;lt;none&amp;gt;        12800/TCP,11800/TCP   8m4s
skywalking-ui             ClusterIP   10.111.140.232   &amp;lt;none&amp;gt;        80/TCP                8m4s

&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;kubectl port-forward service/skywalking-ui 8080:80

curl http://localhost:8080
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>ECK notes</title>
      <link>https://wubigo.com/post/elastic-cloud-on-k8s/</link>
      <pubDate>Mon, 02 Nov 2020 18:03:25 +0800</pubDate>
      
      <guid>https://wubigo.com/post/elastic-cloud-on-k8s/</guid>
      <description>

&lt;h2 id=&#34;什么是eck&#34;&gt;什么是ECK&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;Built on the Kubernetes Operator pattern, Elastic Cloud on Kubernetes (ECK) extends the basic Kubernetes orchestration capabilities to support the setup and management of Elasticsearch, Kibana and APM Server on Kubernetes
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;install-elasticsearch-crd&#34;&gt;install Elasticsearch CRD&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;kubectl apply -f https://download.elastic.co/downloads/eck/1.2.1/all-in-one.yaml
kubectl -n elastic-system logs -f statefulset.apps/elastic-operator
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;创建pv-两种方法任选其一&#34;&gt;创建PV(两种方法任选其一)&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;hostPath&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;code&gt;localPath.yaml&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;apiVersion: v1
kind: PersistentVolume
metadata:
  name: es-pv-volume
  labels:
    type: local
spec:
  storageClassName: local-hdd
  capacity:
    storage: 200Gi
  accessModes:
    - ReadWriteOnce
  hostPath:
    path: &amp;quot;/mnt/data&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;Local volume&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Local volumes do not currently support dynamic provisioning&lt;/strong&gt;
&lt;strong&gt;创建目录/mnt/pv&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;code&gt;sc.yaml&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: local-storage
provisioner: kubernetes.io/no-provisioner
volumeBindingMode: WaitForFirstConsumer
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;local-pv.yaml&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;apiVersion: v1
kind: PersistentVolume
metadata:
  name: local-hdd
spec:
  capacity:
    storage: 200Gi
  volumeMode: Filesystem
  accessModes:
  - ReadWriteOnce
  persistentVolumeReclaimPolicy: Delete
  storageClassName: local-hdd
  local:
    path: /mnt/pv/
  nodeAffinity:
    required:
      nodeSelectorTerms:
      - matchExpressions:
        - key: kubernetes.io/hostname
          operator: In
          values:
          - ssh
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;单节点&#34;&gt;单节点&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;es.yml&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;apiVersion: elasticsearch.k8s.elastic.co/v1
kind: Elasticsearch
metadata:
  name: quickstart
spec:
  version: 7.9.3
  nodeSets:
  - name: default
    count: 1
    config:
      node.master: true
      node.data: true
      node.ingest: true
      node.store.allow_mmap: false
    volumeClaimTemplates:
    - metadata:
        name: elasticsearch-data
      spec:
        accessModes:
        - ReadWriteOnce
        resources:
          requests:
            storage: 100Gi
        storageClassName: local-hdd
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;禁用tls&#34;&gt;禁用TLS&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;es-no-tls.yml&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;apiVersion: elasticsearch.k8s.elastic.co/v1
kind: Elasticsearch
metadata:
  name: quickstart
spec:
  version: 7.9.3
  nodeSets:
  - name: default
    count: 1
    config:
      node.master: true
      node.data: true
      node.ingest: true
      node.store.allow_mmap: false
    volumeClaimTemplates:
    - metadata:
        name: elasticsearch-data
      spec:
        accessModes:
        - ReadWriteOnce
        resources:
          requests:
            storage: 100Gi
        storageClassName: local-hdd
  http:
    tls:
      selfSignedCertificate:
        disabled: true

&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;kubectl get elasticsearch
NAME         HEALTH   NODES   VERSION   PHASE   AGE
quickstart   green    1       7.9.3     Ready   50m

&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;检查&#34;&gt;检查&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;kubectl get service quickstart-es-http
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;密码&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;kubectl get secret quickstart-es-elastic-user -o go-template=&#39;{{.data.elastic | base64decode}}&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;kubectl port-forward service/quickstart-es-http 9200


curl -u &amp;quot;elastic:$PASSWORD&amp;quot; -k &amp;quot;https://localhost:9200&amp;quot;

curl -u &amp;quot;elastic:8FfgPZu0985bAm2x4243ncxJ&amp;quot; -k &amp;quot;https://10.101.24.19:9200&amp;quot;



&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;安装kibana&#34;&gt;安装kibana&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;kibana.yml&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;apiVersion: kibana.k8s.elastic.co/v1
kind: Kibana
metadata:
  name: quickstart
spec:
  version: 7.9.3
  count: 1
  elasticsearchRef:
    name: quickstart
    namespace: default
  http:
    tls:
      selfSignedCertificate:
        disabled: true
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;kubectl get svc
NAME                      TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)               AGE
kubernetes                ClusterIP   10.96.0.1        &amp;lt;none&amp;gt;        443/TCP               10h
quickstart-es-default     ClusterIP   None             &amp;lt;none&amp;gt;        9200/TCP              8h
quickstart-es-http        ClusterIP   10.101.24.19     &amp;lt;none&amp;gt;        9200/TCP              8h
quickstart-es-transport   ClusterIP   None             &amp;lt;none&amp;gt;        9300/TCP              8h
quickstart-kb-http        ClusterIP   10.110.209.226   &amp;lt;none&amp;gt;        5601/TCP              15m


kubectl port-forward service/quickstart-kb-http 5601
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;安装filebeat&#34;&gt;安装filebeat&lt;/h2&gt;

&lt;p&gt;Filebeat is a lightweight shipper for forwarding and centralizing log data. Installed as an&lt;/p&gt;

&lt;p&gt;agent on your servers, Filebeat monitors the log files or locations that you specify,&lt;/p&gt;

&lt;p&gt;collects log events, and forwards them either to Elasticsearch or Logstash for indexing.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;curl -L -O https://raw.githubusercontent.com/elastic/beats/7.9/deploy/kubernetes/filebeat-kubernetes.yaml
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;---
apiVersion: v1
kind: ConfigMap
metadata:
  name: filebeat-config  
  labels:
    k8s-app: filebeat
data:
  filebeat.yml: |-
    # filebeat.inputs:
    # - type: container
    #   paths:
    #     - /var/log/containers/*.log
    #   processors:
    #     - add_kubernetes_metadata:
    #         host: ${NODE_NAME}
    #         matchers:
    #         - logs_path:
    #             logs_path: &amp;quot;/var/log/containers/&amp;quot;
    filebeat.autodiscover:
     providers:
       - type: kubernetes
         node: ${NODE_NAME}
         hints.enabled: true
         hints.default_config:
           type: container
           paths:
             - /var/log/containers/*${data.kubernetes.container.id}.log
    processors:
      - add_cloud_metadata:
      - add_host_metadata:
      - add_locale: ~
    cloud.id: ${ELASTIC_CLOUD_ID}
    cloud.auth: ${ELASTIC_CLOUD_AUTH}
    output.elasticsearch:
      hosts: [&#39;http://${ELASTICSEARCH_HOST:elasticsearch}:${ELASTICSEARCH_PORT:9200}&#39;]
      username: ${ELASTICSEARCH_USERNAME}
      password: ${ELASTICSEARCH_PASSWORD}
      ssl.enabled: false
      ssl.certificate_authorities:
      - /mnt/elastic/tls.crt
    setup.dashboards.enabled: true
    setup.kibana:
      host: &amp;quot;http://${KIBANA_HOST}:5601&amp;quot;
      username: ${ELASTICSEARCH_USERNAME}
      password: ${ELASTICSEARCH_PASSWORD}
      protocol: &amp;quot;http&amp;quot;
      ssl.enabled: false
    filebeat.config:
      modules:
        path: ${path.config}/modules.d/*.yml
        reload.enabled: false
    filebeat.modules:
      - module: system
        syslog:
          enabled: true
          var.paths: [&amp;quot;/var/log/messages&amp;quot;]
          var.convert_timezone: true
        auth:
          enabled: true
          var.paths: [&amp;quot;/var/log/secure&amp;quot;]
          var.convert_timezone: true
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: filebeat
  labels:
    k8s-app: filebeat
spec:
  selector:
    matchLabels:
      k8s-app: filebeat
  template:
    metadata:
      labels:
        k8s-app: filebeat
    spec:
      tolerations:
        - key: node-role.kubernetes.io/master
          effect: NoSchedule
      serviceAccountName: filebeat
      terminationGracePeriodSeconds: 30
      hostNetwork: true
      dnsPolicy: ClusterFirstWithHostNet
      containers:
      - name: filebeat
        image: docker.elastic.co/beats/filebeat:7.9.3
        args: [
          &amp;quot;-c&amp;quot;, &amp;quot;/etc/filebeat.yml&amp;quot;,
          &amp;quot;-e&amp;quot;,
        ]
        env:
        - name: ELASTICSEARCH_HOST
          value: quickstart-es-http
        - name: ELASTICSEARCH_PORT
          value: &amp;quot;9200&amp;quot;
        - name: ELASTICSEARCH_USERNAME
          value: elastic
        - name: ELASTICSEARCH_PASSWORD
          valueFrom:
            secretKeyRef:
              key: elastic
              name: quickstart-es-elastic-user
        - name: KIBANA_HOST
          value: quickstart-kb-http
        - name: ELASTIC_CLOUD_ID
          value:
        - name: ELASTIC_CLOUD_AUTH
          value:
        - name: NODE_NAME
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
        securityContext:
          runAsUser: 0
          # If using Red Hat OpenShift uncomment this:
          #privileged: true
        resources:
          limits:
            memory: 200Mi
          requests:
            cpu: 100m
            memory: 100Mi
        volumeMounts:
        - name: config
          mountPath: /etc/filebeat.yml
          readOnly: true
          subPath: filebeat.yml
        - name: data
          mountPath: /usr/share/filebeat/data
        - name: varlibdockercontainers
          mountPath: /var/lib/docker/containers
          readOnly: true
        - name: varlog
          mountPath: /var/log
          readOnly: true
        - name: es-certs
          mountPath: /mnt/elastic/tls.crt
          readOnly: true
          subPath: tls.crt
        - name: localtime
          mountPath: /etc/localtime
          readOnly: true
      volumes:
      - name: config
        configMap:
          defaultMode: 0600
          name: filebeat-config
      - name: varlibdockercontainers
        hostPath:
          path: /var/lib/docker/containers
      - name: varlog
        hostPath:
          path: /var/log
      # data folder stores a registry of read status for all files, so we don&#39;t send everything again on a Filebeat pod restart
      - name: data
        hostPath:
          path: /var/lib/filebeat-data
          type: DirectoryOrCreate
      - name: es-certs
        secret:
          secretName: quickstart-es-http-certs-public
      - name: localtime
        hostPath:
          path: /etc/localtime
          type: File
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: filebeat
subjects:
- kind: ServiceAccount
  name: filebeat
  namespace: default
roleRef:
  kind: ClusterRole
  name: filebeat
  apiGroup: rbac.authorization.k8s.io
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: filebeat
  labels:
    k8s-app: filebeat
rules:
- apiGroups: [&amp;quot;&amp;quot;] # &amp;quot;&amp;quot; indicates the core API group
  resources:
  - namespaces
  - pods
  verbs:
  - get
  - watch
  - list
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: filebeat
  labels:
    k8s-app: filebeat
---

&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>在Ubuntu上禁用DNS本地缓存 </title>
      <link>https://wubigo.com/post/ubuntu-dns-client/</link>
      <pubDate>Thu, 29 Oct 2020 21:59:14 +0800</pubDate>
      
      <guid>https://wubigo.com/post/ubuntu-dns-client/</guid>
      <description>

&lt;p&gt;Linux systems which use a GUI often have a network manager running, which uses a dnsmasq instance running on a loopback address such as 127.0.0.1 or 127.0.1.1 to cache DNS requests, and adds this entry to /etc/resolv.conf. The dnsmasq service speeds up DNS look-ups and also provides DHCP services&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo cat /run/resolvconf/resolv.conf
sudo cat /run/dnsmasq/resolv.conf
sudo cat /etc/systemd/resolved.conf
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;disable-the-local-dns-cache&#34;&gt;Disable the local DNS cache&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;/etc/NetworkManager/NetworkManager.conf&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#dns=dnsmasq
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;systemctl restart network-manager
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;sudo systemctl disable dnsmasq
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;ubuntu-20-04&#34;&gt;ubuntu 20.04&lt;/h2&gt;

&lt;p&gt;双网卡或局域网加无线网主机，路由指向通一个路由器&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ls -l /etc/resolv.conf
/etc/resolv.conf -&amp;gt; /run/systemd/resolve/stub-resolv.conf

unlink /etc/resolv.conf
ln -s /run/systemd/resolve/resolv.conf /etc/resolv.conf


sudo ip route del default  dev wlp2s0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://www.tecmint.com/set-permanent-dns-nameservers-in-ubuntu-debian/&#34; target=&#34;_blank&#34;&gt;https://www.tecmint.com/set-permanent-dns-nameservers-in-ubuntu-debian/&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;更新ip地址&#34;&gt;更新IP地址&lt;/h2&gt;

&lt;p&gt;To renew or release an IP address for the eth0 interface, enter:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;sudo dhclient -r eth0
sudo dhclient eth0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;s&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Setup K8s With Kubeadm</title>
      <link>https://wubigo.com/post/k8s-setup-with-kubeadm/</link>
      <pubDate>Thu, 29 Oct 2020 16:38:33 +0800</pubDate>
      
      <guid>https://wubigo.com/post/k8s-setup-with-kubeadm/</guid>
      <description>

&lt;h2 id=&#34;检查dns&#34;&gt;检查dns&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;sudo cat /etc/resolv.conf
# Dynamic resolv.conf(5) file for glibc resolver(3) generated by resolvconf(8)
#     DO NOT EDIT THIS FILE BY HAND -- YOUR CHANGES WILL BE OVERWRITTEN
nameserver 10.8.3.1
nameserver 114.114.114.114
nameserver 8.8.8.8
nameserver 114.114.114.114
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://wubigo.com/post/ubuntu-dns-client/&#34;&gt;详细说明&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;安装&#34;&gt;安装&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;kubeadm config images pull --image-repository registry.aliyuncs.com/google_containers
sudo kubeadm init --image-repository registry.aliyuncs.com/google_containers

kubectl apply -f https://docs.projectcalico.org/v3.11/manifests/calico.yaml




kubeadm join 10.8.3.222:6443 --token awon9z.bcw8z \
    --discovery-token-ca-cert-hash sha256:7b90bca7225915f07179fd2ad31820533
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;检查dns-1&#34;&gt;检查DNS&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;kubectl run -it busybox --image=busybox --restart=Never -- sh
If you don&#39;t see a command prompt, try pressing enter.
/ # nslookup kubernetes
Server:         10.96.0.10
Address:        10.96.0.10:53
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;为calico的kdd安装calicoctl-calico-ctl-v3-11-3-pod&#34;&gt;为calico的KDD安装calicoctl(calico/ctl:v3.11.3 POD)&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;kubectl apply -f https://docs.projectcalico.org/manifests/calicoctl.yaml
alias calicoctl=&amp;quot;kubectl exec -i -n kube-system calicoctl -- /calicoctl&amp;quot;
calicoctl get node
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;calicoctl node status用法提示&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;calicoctl的版本必须和calico-node版本一致才能正常工作&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;必须在calico-node所在的节点上运行该命令&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;curl -O -L  https://github.com/projectcalico/calicoctl/releases/download/v3.11.3/calicoctl
export DATASTORE_TYPE=kubernetes
export KUBECONFIG=~/.kube/config
sudo ./calicoctl node status
Calico process is running.

IPv4 BGP status
+--------------+-------------------+-------+------------+-------------+
| PEER ADDRESS |     PEER TYPE     | STATE |   SINCE    |    INFO     |
+--------------+-------------------+-------+------------+-------------+
| 10.8.3.211   | node-to-node mesh | up    | 2020-10-30 | Established |
+--------------+-------------------+-------+------------+-------------+

IPv6 BGP status
No IPv6 peers found.

bigo@bigo-s3:~$ sudo ./calicoctl version
Client Version:    v3.11.3
Git commit:        05f36cc8
no etcd endpoints specified
bigo@bigo-s3:~$ alias calicoctl=&amp;quot;kubectl exec -i -n kube-system calicoctl -- /calicoctl&amp;quot;
bigo@bigo-s3:~$ calicoctl version
Client Version:    v3.16.4
Git commit:        51418082
Cluster Version:   v3.11.3
Cluster Type:      k8s,bgp,kdd
bigo@bigo-s3:~$ calicoctl node status
Calico process is not running.
command terminated with exit code 1

&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&#34;https://docs.projectcalico.org/getting-started/clis/calicoctl/install&#34; target=&#34;_blank&#34;&gt;https://docs.projectcalico.org/getting-started/clis/calicoctl/install&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;ubuntu-20&#34;&gt;ubuntu 20&lt;/h2&gt;

&lt;p&gt;安装完后确保没有使用本地DNS缓存&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;unlink /etc/resolv.conf
ln -s /run/systemd/resolve/resolv.conf  /etc/resolv.conf
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;[FATAL][1783] int_dataplane.go 1035: Kernel&#39;s RPF check is set to &#39;loose&#39;.  This would allow endpoints to spoof their IP address.  Calico requires net.ipv4.conf.all.rp_filter to be set to 0 or 1. If you require loose RPF and you are not concerned about spoofing, this check can be disabled by setting the IgnoreLooseRPF configuration parameter to &#39;true&#39;.
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;kubectl -n kube-system set env daemonset/calico-node FELIX_IGNORELOOSERPF=true
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;重新安装&#34;&gt;重新安装&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;kubeadm reset
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;刷新所有的链（-F），删除所有的非默认链（-X）&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;iptables -F
iptables -X

iptables -nvL
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;kubeadm token create --print-join-command
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>容器工具--Skafflod</title>
      <link>https://wubigo.com/post/skafflod/</link>
      <pubDate>Thu, 29 Oct 2020 09:36:06 +0800</pubDate>
      
      <guid>https://wubigo.com/post/skafflod/</guid>
      <description>

&lt;h2 id=&#34;安装kubectl&#34;&gt;安装kubectl&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;curl https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | apt-key add - 
cat &amp;lt;&amp;lt;EOF &amp;gt;/etc/apt/sources.list.d/kubernetes.list
deb https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial main
EOF  
apt-get update
apt-get install -y kubectl=1.18.3-00
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Installing bash completion on Linux&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;kubectl completion bash &amp;gt; ~/.kube/kubectl.bash.inc
printf &amp;quot;
# Kubectl shell completion
source &#39;$HOME/.kube/kubectl.bash.inc&#39;
&amp;quot; &amp;gt;&amp;gt; $HOME/.bashrc
source $HOME/.bashrc
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code&gt;git clone git@github.com:GoogleCloudPlatform/microservices-demo.git 
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;cat /etc/docker/daemon.json

{
  &amp;quot;insecure-registries&amp;quot; : [&amp;quot;10.8.5.211&amp;quot;]
}

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;microservices-demo/src/shippingservice/Dockerfile&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;RUN go env -w GOPROXY=https://goproxy.cn,direct 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;microservices-demo/src/recommendationservice/Dockerfile&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ENV DISABLE_DEBUGGER=1
ENV DISABLE_PROFILER=1
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;skaffold run --default-repo=10.8.5.211/library
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;kubectl port-forward deployment/frontend 8080:8080
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Wireguad Vpn Client for Ubuntu</title>
      <link>https://wubigo.com/post/wireguard-vpn-client-for-ubuntu/</link>
      <pubDate>Mon, 31 Aug 2020 12:41:39 +0800</pubDate>
      
      <guid>https://wubigo.com/post/wireguard-vpn-client-for-ubuntu/</guid>
      <description>

&lt;h2 id=&#34;安装&#34;&gt;安装&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;sudo apt install wireguard  wireguard-dkms -y
wget algo/configs/localhost/wireguard/desktop.conf  /etc/wireguard/wg0.conf
sudo wg-quick up wg0
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Nginx Root vs Alias</title>
      <link>https://wubigo.com/post/nginx-root-vs-alias/</link>
      <pubDate>Thu, 20 Aug 2020 15:25:18 +0800</pubDate>
      
      <guid>https://wubigo.com/post/nginx-root-vs-alias/</guid>
      <description>&lt;p&gt;There is a very important difference between the root and the alias directives. This difference exists in the way the path specified in the root or the alias is processed.&lt;/p&gt;

&lt;p&gt;In case of the root directive, full path is appended to the root including the location part, whereas in case of the alias directive, only the portion of the path NOT including the location part is appended to the alias.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;location /beta {
  root /var/www/html
  
}

location /beta {
  alias /var/www/html/beta
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;a href=&#34;https://stackoverflow.com/questions/10631933/nginx-static-file-serving-confusion-with-root-alias&#34; target=&#34;_blank&#34;&gt;https://stackoverflow.com/questions/10631933/nginx-static-file-serving-confusion-with-root-alias&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Cloud Native Data Center Network</title>
      <link>https://wubigo.com/post/cloud-native-data-center-network/</link>
      <pubDate>Tue, 18 Aug 2020 15:57:57 +0800</pubDate>
      
      <guid>https://wubigo.com/post/cloud-native-data-center-network/</guid>
      <description>

&lt;h2 id=&#34;inline-versus-overlay-virtual-networks&#34;&gt;Inline Versus Overlay Virtual Networks&lt;/h2&gt;

&lt;p&gt;In the inline model, every hop between the source and destination is aware of the virtual network the packet belongs to and uses this information to do lookups in the forwarding table. In the overlay network model, only the edges of the network keep track of the virtual networks; the core of the network is unaware of virtual networks. VLAN and VRF are examples of the inline model of virtual networks, whereas MPLS, VXLAN, and other IP-based VPNs are examples of the overlay model. I’ve encountered customer deployments where 32 to 64 VRFs were used&lt;/p&gt;

&lt;p&gt;The primary benefits of the inline model are transparency and reduced packet header overhead. However, requiring every node along the path be aware of virtual networks makes the model very unscalable and inefficient. It scales poorly because, as we get to the core of the network, the core devices must keep track of every single virtual network to forward packets properly. It is inefficient because any change to the virtual network affects every node in the network. The more moving parts there are, the more possibility there is of introducing an error and causing unexpected problems. Anybody who has deployed VLANs is well aware of these two problems. The same holds for VRFs, as well&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>V8 Isolates</title>
      <link>https://wubigo.com/post/v8-isolates/</link>
      <pubDate>Wed, 29 Jul 2020 15:28:40 +0800</pubDate>
      
      <guid>https://wubigo.com/post/v8-isolates/</guid>
      <description>&lt;p&gt;Isolate represents an isolated instance of the V8 engine. V8 isolates have completely separate states. Objects from one isolate must not be used in other isolates. When V8 is initialized a default isolate is implicitly created and entered. The embedder can create additional isolates and use them in parallel in multiple threads. An isolate can be entered by at most one thread at any given time. The Locker/Unlocker API must be used to synchronize.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://v8docs.nodesource.com/node-0.8/d5/dda/classv8_1_1_isolate.html&#34; target=&#34;_blank&#34;&gt;https://v8docs.nodesource.com/node-0.8/d5/dda/classv8_1_1_isolate.html&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>网关授权之函数实现</title>
      <link>https://wubigo.com/post/api-gateway-lambda-authorizer/</link>
      <pubDate>Sun, 26 Jul 2020 07:39:23 +0800</pubDate>
      
      <guid>https://wubigo.com/post/api-gateway-lambda-authorizer/</guid>
      <description>

&lt;h2 id=&#34;setting-up-the-hosted-ui-with-the-amazon-cognito&#34;&gt;Setting Up the Hosted UI with the Amazon Cognito&lt;/h2&gt;

&lt;p&gt;Unless required by your authorization flow, clear the option &lt;strong&gt;&lt;em&gt;Generate client secret&lt;/em&gt;&lt;/strong&gt;. The client secret is used by applications that have a server-side component that can secure the client secret&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Lambda Proxy vs Lambda Integration</title>
      <link>https://wubigo.com/post/lambda-proxy-vs-lambda-integration/</link>
      <pubDate>Sat, 18 Jul 2020 20:34:43 +0800</pubDate>
      
      <guid>https://wubigo.com/post/lambda-proxy-vs-lambda-integration/</guid>
      <description>

&lt;h2 id=&#34;lambda-proxy-vs-lambda-integration&#34;&gt;Lambda Proxy vs Lambda Integration&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/vaquarkhan/vaquarkhan/wiki/Lambda-Proxy-vs-Lambda-Integration-in-AWS-API-Gateway&#34; target=&#34;_blank&#34;&gt;https://github.com/vaquarkhan/vaquarkhan/wiki/Lambda-Proxy-vs-Lambda-Integration-in-AWS-API-Gateway&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;python&#34;&gt;PYTHON&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://realpython.com/code-evaluation-with-aws-lambda-and-api-gateway/&#34; target=&#34;_blank&#34;&gt;https://realpython.com/code-evaluation-with-aws-lambda-and-api-gateway/&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;java&#34;&gt;JAVA&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://www.baeldung.com/aws-lambda-api-gateway&#34; target=&#34;_blank&#34;&gt;https://www.baeldung.com/aws-lambda-api-gateway&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;git clone https://github.com/eugenp/tutorials.git
cd tutorials/aws-lambda
mvn clean package shade:shade
aws s3 cp ./target/aws-lambda-0.1.0-SNAPSHOT.jar s3://wubigo/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;从S3上传文件到lambad&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;handler&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;com.baeldung.lambda.apigateway.APIDemoHandler::handleRequest
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;nodejs&#34;&gt;NODEJS&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://itnext.io/how-to-build-a-serverless-app-with-s3-and-lambda-in-15-minutes-b14eecd4ea89&#34; target=&#34;_blank&#34;&gt;https://itnext.io/how-to-build-a-serverless-app-with-s3-and-lambda-in-15-minutes-b14eecd4ea89&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Lambda之任务定时调度</title>
      <link>https://wubigo.com/post/lambda-schedule-event/</link>
      <pubDate>Wed, 15 Jul 2020 19:23:47 +0800</pubDate>
      
      <guid>https://wubigo.com/post/lambda-schedule-event/</guid>
      <description>

&lt;p&gt;函数计算有很多使用场景，今天介绍定时任务调度&lt;/p&gt;

&lt;p&gt;例如每周六生成业务报表&lt;/p&gt;

&lt;h2 id=&#34;事件类别&#34;&gt;事件类别&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;资源生命周期事件&lt;/li&gt;
&lt;li&gt;HTTP请求&lt;/li&gt;
&lt;li&gt;消息队列&lt;/li&gt;
&lt;li&gt;调度&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;调度事件&#34;&gt;调度事件&lt;/h2&gt;

&lt;p&gt;define event rules that self-trigger regularly and configure a target action to do some regular work. So you can define an Amazon Lambda function or AWS Step Functions state machine as scheduled targets. Hence, when this event is triggered at the specified time or interval you defined, your function or state machine is executed. These types of events are called scheduled Amazon CloudWatch Events&lt;/p&gt;

&lt;h2 id=&#34;定义调度&#34;&gt;定义调度&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;cron 表达式&lt;/li&gt;
&lt;li&gt;rate 表达式&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;函数调用网关接口类型&#34;&gt;函数调用网关接口类型&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;HTTP API：A lightweight, low-latency RESTful API(Gateway version 2 API)&lt;/li&gt;
&lt;li&gt;REST API：A customizable, feature-rich RESTful API&lt;/li&gt;
&lt;li&gt;WebSocket API&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;http-api-features&#34;&gt;HTTP API features&lt;/h3&gt;

&lt;p&gt;Automatic deployments – When you modify routes or integrations, changes deploy automatically to stages that have automatic deployment enabled.&lt;/p&gt;

&lt;p&gt;Default stage – You can create a default stage ($default) to serve requests at the root path of your API&amp;rsquo;s URL. For named stages, you must include the stage name at the beginning of the path.&lt;/p&gt;

&lt;p&gt;CORS configuration – You can configure your API to add CORS headers to outgoing responses, instead of adding them manually in your function code.&lt;/p&gt;

&lt;p&gt;REST APIs are the classic RESTful APIs that API Gateway has supported since launch. REST APIs currently have more customization, integration, and management features.&lt;/p&gt;

&lt;h3 id=&#34;rest-api-features&#34;&gt;REST API features&lt;/h3&gt;

&lt;p&gt;Integration types – REST APIs support custom Lambda integrations. With a custom integration, you can send just the body of the request to the function, or apply a transform template to the request body before sending it to the function.&lt;/p&gt;

&lt;p&gt;Access control – REST APIs support more options for authentication and authorization.&lt;/p&gt;

&lt;p&gt;Monitoring and tracing – REST APIs support AWS X-Ray tracing and additional logging options.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Python3 Notes</title>
      <link>https://wubigo.com/post/python3-notes/</link>
      <pubDate>Tue, 14 Jul 2020 19:44:56 +0800</pubDate>
      
      <guid>https://wubigo.com/post/python3-notes/</guid>
      <description>

&lt;h2 id=&#34;python-镜像&#34;&gt;PYTHON 镜像&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;ERROR: Could not install packages due to an EnvironmentError:
HTTPSConnectionPool(host=&amp;lsquo;files.pythonhosted.org&amp;rsquo;, port=443)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;code&gt;$HOME/.config/pip/pip.conf&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[global]

trusted-host=mirrors.aliyun.com

index-url=http://mirrors.aliyun.com/pypi/simple/
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;windows-10&#34;&gt;WINDOWS 10&lt;/h2&gt;

&lt;pre&gt;&lt;code&gt;Python 3.6.8
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;  File &amp;quot;C:\code\venv3\lib\site-packages\pip\_vendor\distlib\scripts.py&amp;quot;, line 383, in _get_launcher
    raise ValueError(msg)
ValueError: Unable to find resource t64.exe in package pip._vendor.distlib
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;python -m pip uninstall pip
python -m ensurepip
python -m pip install -U pip
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Serveless Python Zappa</title>
      <link>https://wubigo.com/post/serveless-python-zappy/</link>
      <pubDate>Tue, 14 Jul 2020 14:02:13 +0800</pubDate>
      
      <guid>https://wubigo.com/post/serveless-python-zappy/</guid>
      <description>

&lt;h2 id=&#34;python3&#34;&gt;python3&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;改变操作系统的地区为美国&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;否则报UnicodeDecodeError: &amp;lsquo;gbk&amp;rsquo; codec can&amp;rsquo;t decode&lt;/p&gt;

&lt;p&gt;&lt;code&gt;python-3.6.8-amd64&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;py -3.6 -m pip install virtualenv
py -3.6 -m virtualenv venv3
.\venv3\script\activate
pip install zappa

git clone https://github.com/Miserlou/Zappa.git
cd zappy/example
pip install flask
zappa deploy dev_event
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;检查状态&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;zappa  status dev_api
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;faq&#34;&gt;FAQ&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;IllegalLocationConstraintException&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;get this error if you&#39;re trying to create a bucket with a name that&#39;s already been taken

&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&#34;https://stackoverflow.com/questions/49174673/aws-s3api-create-bucket-bucket-make-exception&#34; target=&#34;_blank&#34;&gt;https://stackoverflow.com/questions/49174673/aws-s3api-create-bucket-bucket-make-exception&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;--create-bucket-configuration LocationConstraint=eu-west-1
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
  </channel>
</rss>
